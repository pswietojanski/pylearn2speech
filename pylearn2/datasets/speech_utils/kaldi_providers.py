__authors__ = "Pawel Swietojanski"
__copyright__ = "Copyright 2013, University of Edinburgh"
__credits__ = ["Pawel Swietojanski"]
__license__ = "3-clause BSD"
__maintainer__ = "Pawel Swietojanski"
__email__ = "p.swietojanski@ed.ac.uk"

import numpy
import struct
import random
import logging
import cPickle
import os

from multiprocessing import Process, Queue, Pool

from string import Template
from StringIO import StringIO
from pylearn2.datasets.speech_utils.providers import ListDataProvider, make_shell_call
from pylearn2.space import CompositeSpace, Conv2DSpace, VectorSpace

log = logging.getLogger(__name__)


def read_kaldi_matrix(buffer, skip_binary_preamble=False):

    if skip_binary_preamble:
        descr = struct.unpack('<ccc', buffer.read(5))  # read 0B{F,D}{V,M,C}[space], function tested for 0BFM types only
        repr_type = descr[0]
        cont_type = descr[1]
    else:
        descr = struct.unpack('<xcccc', buffer.read(5))  # read 0B{F,D}{V,M,C}[space], function tested for 0BFM types only
        binary_mode = descr[0]
        repr_type = descr[1]
        cont_type = descr[2]
        assert binary_mode == "B"

    if (repr_type == 'F'):
        dtype = numpy.dtype(numpy.float32)
    elif (repr_type == 'D'):
        dtype = numpy.dtype(numpy.float64)
    else:
        raise ValueError('Wrong representation type in Kaldi header (is feats '
                        'compression enabled? - this is not supported in the '
                        'current version. Feel free to add this functionality.): %c' % (repr_type))

    rows, cols = 1, 1
    if (cont_type == 'M'):
        p1, rows = struct.unpack('<bi', buffer.read(5))  # bytes from 5 to 10
        p2, cols = struct.unpack('<bi', buffer.read(5))  # bytes from 10 to 15
        assert p1 == 4 and p2 == 4  # Number of bytes dimensionality is stored?
    elif (cont_type == 'V'):
        p1, rows = struct.unpack('<bi', buffer.read(5))  # bytes from 5 to 10
        assert p1 == 4
    else:
        raise Exception('Wrong container type in Kaldi header: %c' % (cont_type))

    assert rows > 0 and cols > 0  # just a range sanity checks
    assert rows < 360000 and cols < 30000  # just a sensible range sanity checks

    result = numpy.frombuffer(buffer.read(rows * cols * dtype.itemsize), dtype=dtype)
    if (cont_type == 'M'):
        result = numpy.reshape(result, (rows, cols))

    return result


def read_uttid(buffer):
    uttid = ''
    c = buffer.read(1)
    while c != ' ' and c != '':
        uttid += c
        c = buffer.read(1)
    return uttid


def read_ark_entry_from_buffer(buffer):
    """Reads a single Kaldi table archive entry and returns a tuple (uttid, ndarray)"""
    uttid = read_uttid(buffer)
    if uttid == '':
        return ''  # sygnalize EOF or pipe
    mtrx = None
    try:
        mtrx = read_kaldi_matrix(buffer)  # if this fails will raise (some) exception
    except Exception as e:
        raise e
    return (uttid, mtrx)


def read_ark_entry_from_archive(scp_entry):
    """Reads a single Kaldi table archive entry and returns a numpy array"""

    uttid, path = scp_entry.split(" ")
    ark_path, file_pos = path.split(":")

    try:
        ark = open(ark_path, 'rb')
        ark.seek(int(file_pos))
        feats = read_kaldi_matrix(ark)
        ark.close()
    except Exception as e:
        raise e

    return feats


def write_ark_entry_to_buffer(buffer, uttid, activations):
    activations = numpy.asarray(activations, dtype='float32')
    rows, cols = activations.shape
    buffer.write(struct.pack('<%ds' % (len(uttid)), uttid))
    buffer.write(struct.pack('<cxcccc', ' ', 'B', 'F', 'M', ' '))
    buffer.write(struct.pack('<bi', 4, rows))
    buffer.write(struct.pack('<bi', 4, cols))
    buffer.write(activations)


def read_kaldi_aligns(align_filename):
    f = open(align_filename, 'r')
    align_info = {}
    num_lines_align, num_examples, num_classes = 0, 0, 0
    for line in f:
        num_lines_align += 1
        line = line.strip()
        if len(line) < 1:
            continue  # remove empty lines
        [utt, alignment] = line.split(' ', 1)
        # skip empty alignments (these shouldn't be generated by Kaldi anyway)
        if len(alignment) < 1:
            log.warning('Empty alignment for utterance %s' % utt)
            continue
        align_info[utt] = numpy.loadtxt(StringIO(alignment), dtype=numpy.int32)
        tmp = align_info[utt].max()
        if tmp > num_classes:
            num_classes = tmp
        num_examples += align_info[utt].shape[0]
    f.close()
    return align_info, num_examples, num_classes


class KaldiFeatsProviderUtt(ListDataProvider):
    def __init__(self,
                 feats_scp,
                 feats_dim,
                 template_shell_command=None,  # "copy-feats-1file scp:\"echo ${SCP_ENTRY}|\"",
                 randomize=False,
                 max_utt=-1):
        """

        :param feats_scp:
        :param dim:
        :param template_shell_command:
        :param randomize:
        :param max_utt:
        :return:
        """

        super(KaldiFeatsProviderUtt, self).__init__(feats_scp)
        self.max_utt = max_utt
        self.randomize = randomize
        self.template_shell_command = (
            Template(template_shell_command) if (template_shell_command != None) else None)
        self.feats_dim = feats_dim
        if self.randomize is True:
            random.shuffle(self.files_list)

        self.data_specs = (VectorSpace(dim=self.feats_dim), 'features')

    def reset(self):
        self.index = 0
        if self.randomize is True:
            random.shuffle(self.files_list)

    def __iter__(self):
        return self

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            raise StopIteration

        utt_path = self.files_list[self.index]
        features = None
        try:
            if self.template_shell_command is None:
                features = read_ark_entry_from_archive(utt_path)
            else:
                features = self.shell_call(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipping.' % e)
        self.index += 1

        return features

    def shell_call(self, utt_path):

        shell_call_cmd = self.template_shell_command.substitute(SCP_ENTRY=utt_path)
        buffer_tuple = make_shell_call(shell_call_cmd)

        if buffer_tuple is None:
            raise Exception('Cannot extract a matrix using shell call %s .' % shell_call_cmd)

        features = read_kaldi_matrix(StringIO(buffer_tuple[0]))

        return (features,)

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_specs


class KaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    """Data provider reading Kaldi archives and returning utterance-based
    features and associated ground-truth labels from alignment files
    """

    def __init__(self,
                 feats_scp,
                 aligns_scp,
                 feats_dim,
                 targets_dim,
                 template_shell_command=None,
                 randomize=False,
                 max_time=-1,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False,
                 ret_utt_scps=False):
        """

        :param feats_scp:
        :param aligns_scp:
        :param template_shell_command:
        :param randomize:
        :param max_time:
        :param max_utt:
        :param frame_shift:
        :param mapped:
        :return: a tuple (features, targets) for a given utterance
        """

        super(KaldiAlignFeatsProviderUtt, self).\
            __init__(feats_scp=feats_scp,
                    feats_dim=feats_dim,
                    template_shell_command=template_shell_command,
                    randomize=randomize,
                    max_utt=max_utt)

        self.frame_shift = frame_shift
        self.targets_dim = targets_dim
        self.mapped = mapped
        self._frame_shift_in_sec = self.frame_shift / 1000.0
        self.utt_skipped = 0
        self._num_examples = 0
        self.ret_utt_scps = ret_utt_scps

        files_info = {}
        for scp_entry in self.files_list:
            [utt, path] = scp_entry.split(' ', 1)
            files_info[utt] = scp_entry

        try:
            align_info, num_examples, num_classes = \
                read_kaldi_aligns(aligns_scp)
        except IOError as e:
            raise e

        fi_set = set(files_info.keys())
        ai_set = set(align_info.keys())
        iset = set.intersection(fi_set, ai_set)

        #monophones in Kaldi are indexed from 1, mapp
        # this to 0-based indexing
        mapping = 0
        if self.mapped:
            log.warning("Mapping indexing from 1-based to 0-based (Kaldi monophones)")
            mapping = 1

        self.files_info, self.align_info = {}, {}
        for k in iset:
            self.files_info[k] = files_info[k]
            self.align_info[k] = align_info[k] - mapping

        assert len(self.align_info) == len(self.files_info)
        self._num_examples = self._recount_examples(self.align_info)

        assert self._num_examples > 0, (
            "Did not found matched alignments for the given feat (%s) "
            "and align files (%s)" % (feats_scp, aligns_scp)
        )

        log.warning("Loaded %i feature files and %i associated alignments" \
                    % (len(files_info), len(align_info)))
        log.warning("The intersection of those give in total %i "
                    "data-points." % self._num_examples)
        log.warning("Num of classes found in alignemnts is %i." % num_classes)

        # when asked only subset of data, limit the lists here (given they are large enough at first place)
        # and update corresponding statistics
        if 0 < max_time < (self._num_examples * self._frame_shift_in_sec):
            log.warning('Limiting subset to %d seconds' % max_time)
            self.randomize = False
            new_aligns_info = {}
            new_files_list = []
            examples_loaded, idx = 0, 0
            while examples_loaded * self._frame_shift_in_sec < max_time:
                scp_entry = self.files_list[idx]
                idx += 1
                [utt, path] = scp_entry.split(' ', 1)
                if utt not in self.align_info:
                    continue
                new_files_list.append(scp_entry)
                new_aligns_info[utt] = self.align_info[utt]
                examples_loaded += new_aligns_info[utt].shape[0]

            # alter variables w.r.t new timings
            self.align_info = new_aligns_info
            self.files_list = new_files_list
            self.list_size = len(self.files_list)
            self._num_examples = examples_loaded  # to make Trainer happy it showed all examples it supposed to

        feats_space = VectorSpace(dim=self.feats_dim)
        targets_space = VectorSpace(dim=self.targets_dim)
        self.data_spec = (CompositeSpace((feats_space, targets_space)), ('features', 'targets'))

    def _recount_examples(self, align_info):
        num_examples = 0
        for align in align_info.keys():
            num_examples += numpy.prod(align_info[align].shape)
        return num_examples

    def __iter__(self):
        return self

    def reset(self):
        super(KaldiAlignFeatsProviderUtt, self).reset()
        self.utt_skipped = 0

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            if self.utt_skipped > 0:
                log.warning('KaldiAlignFeatsProviderUtt: Skipped %i utterances out of %i' % (
                    self.utt_skipped, len(self.files_list)))
            raise StopIteration

        utt_path = self.files_list[self.index]
        utt_id = utt_path.split(" ")[0]
        features, labels = None, None
        try:
            if self.template_shell_command is None:
                features = read_ark_entry_from_archive(utt_path)
            else:
                features = self.shell_call(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipping.' % e)

        self.index += 1

        if features is None:
            return None, None

        if utt_id in self.align_info:
            labels = self.align_info[utt_id]
        else:
            self.utt_skipped += 1
            return features, None

        # that shouldn't happen at this point
        if features.shape[0] != labels.shape[0]:
            log.warning('Alignments for %s have %i frames while the utt has %i. Skipping' % \
                        (utt_path, labels.shape[0], features.shape[0]))
            self.utt_skipped += 1
            return features, None

        return features, labels

    def num_classes(self):
        return [self.targets_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class KaldiSATAlignFeatsProviderUtt(KaldiAlignFeatsProviderUtt):
    """Data provider reading Kaldi archives and returning utterance-based
    features and associated ground-truth labels from alignment files
    """

    def __init__(self,
                 feats_scp,
                 aligns_scp,
                 feats_dim,
                 targets_dim,
                 utt2spk_map=None,
                 fake_utt2spk_map=False,
                 si_sd_training_ratio=0.1,
                 si_sd_per_epoch=False,
                 template_shell_command=None,
                 randomize=False,
                 max_time=-1,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False):
        """

        :param feats_scp:
        :param aligns_scp:
        :param template_shell_command:
        :param randomize:
        :param max_time:
        :param max_utt:
        :param frame_shift:
        :param mapped:
        :return: a tuple (features, targets) for a given utterance
        """

        super(KaldiSATAlignFeatsProviderUtt, self).\
            __init__(feats_scp=feats_scp,
                     aligns_scp=aligns_scp,
                    feats_dim=feats_dim,
                    targets_dim=targets_dim,
                    template_shell_command=template_shell_command,
                    randomize=randomize,
                    max_time=max_time,
                    max_utt=max_utt,
                    frame_shift=frame_shift,
                    mapped=mapped)

        self.fake_utt2spk_map = fake_utt2spk_map
        self.si_sd_training_ratio = si_sd_training_ratio
        self.si_sd_per_epoch = si_sd_per_epoch

        if not self.fake_utt2spk_map:
            assert utt2spk_map is not None
            self.utt2spk_and_idx = {} #keeps {utt:[spk idx]}
            spk2idx = {}
            with open(utt2spk_map, 'r') as f:
                for line in f:
                    utt, spk = line.strip().split(None, 1)
                    if spk not in spk2idx.keys():
                        if len(spk2idx) == 0:
                            spk2idx[spk] = 1
                        else:
                            spk2idx[spk] = max(spk2idx.values())+1
                    self.utt2spk_and_idx[utt] = [spk, spk2idx[spk]]

            log.warning('Found %d distinct speakers in data' % len(spk2idx))
        else:
            log.warning('Speaker labels will be faked, but data specs'
                        'will stay compatible with the expected one for sat interface.')

        feats_space = VectorSpace(dim=self.feats_dim)
        spk_idx_space = VectorSpace(dim=1)
        targets_space = VectorSpace(dim=self.targets_dim)
        self.data_spec = (CompositeSpace([feats_space, targets_space, spk_idx_space]), ('features', 'targets', 'speaker_indexes'))

    def __iter__(self):
        return self

    def reset(self):
        super(KaldiSATAlignFeatsProviderUtt, self).reset()

    def next(self):

        try:
            features, labels = super(KaldiSATAlignFeatsProviderUtt, self).next()
        except StopIteration:
            raise StopIteration

        spk_idx_mbatch = None
        if (features is not None and labels is not None):
            if self.fake_utt2spk_map or self.si_sd_training_ratio == 1.0:
                spk_idx_mbatch = numpy.zeros_like(labels)
            else:
                utt_path = self.files_list[self.index-1] #ugly way to do so!
                utt = utt_path.split(" ")[0]
                spk_idx = self.utt2spk_and_idx[utt][1]
                spk_idx_mbatch = numpy.ones_like(labels)*spk_idx

                if self.si_sd_training_ratio is not None \
                        and self.si_sd_training_ratio > 0:

                    assert self.si_sd_training_ratio < 1.0, (
                        "si_sd_training_ratio expected to be "
                        "between 0.0 and 1.0, got %f" % self.si_sd_training_ratio
                    )

                    bsize = spk_idx_mbatch.shape[0]
                    #size = int(bsize*self.si_sd_training_ratio)
                    indexes = numpy.random.binomial(1, self.si_sd_training_ratio, bsize)
                    #print 'Indexes are', indexes
                    spk_idx_mbatch[numpy.where(indexes == 1)] = 0 #at 0th idx speaker-independent transform is kept

        return features, labels, spk_idx_mbatch

    def num_classes(self):
        return [self.targets_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class KaldiSATPerSpkAlignFeatsProviderUtt(KaldiAlignFeatsProviderUtt):
    """Data provider reading Kaldi archives and returning utterance-based
    features and associated ground-truth labels from alignment files
    this variant makes sampling at the segments level
    """

    def __init__(self,
                 feats_scp,
                 aligns_scp,
                 feats_dim,
                 targets_dim,
                 utt2spk_map=None,
                 utt2spk_and_idx_pickle=False,
                 fake_utt2spk_map=False,
                 si_sd_training_ratio=0.1,
                 si_sd_per_segment=False,
                 template_shell_command=None,
                 randomize=False,
                 max_time=-1,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False):
        """

        :param feats_scp:
        :param aligns_scp:
        :param template_shell_command:
        :param randomize:
        :param max_time:
        :param max_utt:
        :param frame_shift:
        :param mapped:
        :return: a tuple (features, targets) for a given utterance
        """

        super(KaldiSATPerSpkAlignFeatsProviderUtt, self).\
            __init__(feats_scp=feats_scp,
                     aligns_scp=aligns_scp,
                    feats_dim=feats_dim,
                    targets_dim=targets_dim,
                    template_shell_command=template_shell_command,
                    randomize=randomize,
                    max_time=max_time,
                    max_utt=max_utt,
                    frame_shift=frame_shift,
                    mapped=mapped)

        self.fake_utt2spk_map = fake_utt2spk_map
        self.si_sd_training_ratio = si_sd_training_ratio
        self.si_sd_per_segment = si_sd_per_segment
        self.utt2spk_and_idx_pickle = utt2spk_and_idx_pickle

        if not self.fake_utt2spk_map and not self.utt2spk_and_idx_pickle:

            assert utt2spk_map is not None
            self.utt2spk_and_idx = {} #keeps {utt:[spk idx]}
            spk2idx = {}
            with open(utt2spk_map, 'r') as f:
                for line in f:
                    utt, spk = line.strip().split(None, 1)
                    if spk not in spk2idx.keys():
                        if len(spk2idx) == 0:
                            spk2idx[spk] = 1
                        else:
                            spk2idx[spk] = max(spk2idx.values())+1
                    self.utt2spk_and_idx[utt] = [spk, spk2idx[spk]]

            log.warning('Found %d distinct speakers in data' % len(spk2idx))

            #now sample SI/SD speaker (which will be kept fixed like this) through
            #the experiment
            if self.si_sd_per_segment is False:
                num_spk = max(spk2idx.values())
                cut_off = int(self.si_sd_training_ratio * num_spk)
                si_spk_ids = (numpy.random.permutation(numpy.arange(1, num_spk))[0:cut_off]).tolist()
                log.warning('Speaker ids set to be treated as independent (%f in total) %s' % (cut_off, si_spk_ids))
            else:
                log.warning('Will sample SI/SD data per segment.')

            log.warning("SAT mode: per speaker (%i), per segment (%i)"
                        % (not self.si_sd_per_segment, self.si_sd_per_segment))

            si_segments, sd_segments = 0, 0
            for utt, (spk, idx) in self.utt2spk_and_idx.items():
                if self.si_sd_per_segment is False:
                    if idx in si_spk_ids:
                        self.utt2spk_and_idx[utt] = [spk, 0] #0 sets it to SI
                        si_segments += 1
                    else:
                        sd_segments += 1
                else:
                    si_or_sd = numpy.random.binomial(1, self.si_sd_training_ratio, 1)
                    if si_or_sd == 1:
                        self.utt2spk_and_idx[utt] = [spk, 0] #0 sets it to SI
                        si_segments += 1
                    else:
                        sd_segments += 1

            log.warning("In total, %i segments is treated as SI, leaving %i as SD." % (si_segments, sd_segments))

            #dump the dictionary, so one can reproduce the exact mapping and use it for sequence training, for exmaple
            fpath = '%s/utt2spk_and_idx.pkl' % os.environ['PYLEARN2_EXP_NAME']
            log.warning("Saving the utt2spk_and_idx mapping dictionary in %s." % fpath)
            with open(fpath, 'w') as f:
                cPickle.dump(self.utt2spk_and_idx, f)

        elif self.utt2spk_and_idx_pickle:
            log.warning('Speaker labels will be loaded from the pickle')
            with open('%s/utt2spk_and_idx.pkl' % os.environ['PYLEARN2_EXP_NAME'], 'r') as f:
                self.utt2spk_and_idx = cPickle.load(f)
        else:
            log.warning('Speaker labels will be faked, but data specs'
                        'will stay compatible with the expected one for sat interface.')

        feats_space = VectorSpace(dim=self.feats_dim)
        spk_idx_space = VectorSpace(dim=1)
        targets_space = VectorSpace(dim=self.targets_dim)
        self.data_spec = (CompositeSpace([feats_space, targets_space, spk_idx_space]), ('features', 'targets', 'speaker_indexes'))

    def __iter__(self):
        return self

    def reset(self):
        super(KaldiSATPerSpkAlignFeatsProviderUtt, self).reset()

    def next(self):

        try:
            features, labels = super(KaldiSATPerSpkAlignFeatsProviderUtt, self).next()
        except StopIteration:
            raise StopIteration

        spk_idx_mbatch = None
        if (features is not None and labels is not None):
            if self.fake_utt2spk_map or self.si_sd_training_ratio == 1.0:
                spk_idx_mbatch = numpy.zeros_like(labels)
            else:
                utt_path = self.files_list[self.index - 1] #ugly way to do so!
                utt = utt_path.split(" ")[0]
                spk_idx = self.utt2spk_and_idx[utt][1]
                spk_idx_mbatch = numpy.ones_like(labels)*spk_idx

        return features, labels, spk_idx_mbatch

    def num_classes(self):
        return [self.targets_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class KaldiSeqAlignFeatsProviderUtt(KaldiAlignFeatsProviderUtt):
    """Data provider reading Kaldi archives and returning utterance-based
    features and associated ground-truth labels from alignment files
    """

    def __init__(self,
                 feats_scp,
                 aligns_scp,
                 lat_scp,
                 feats_dim,
                 targets_dim,
                 fake_lats=False,
                 template_shell_command=None,
                 randomize=False,
                 max_time=-1,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False):
        """

        :param feats_scp:
        :param aligns_scp:
        :param template_shell_command:
        :param randomize:
        :param max_time:
        :param max_utt:
        :param frame_shift:
        :param mapped:
        :return: a tuple (features, targets) for a given utterance
        """

        super(KaldiSeqAlignFeatsProviderUtt, self).\
            __init__(feats_scp=feats_scp,
                     aligns_scp=aligns_scp,
                    feats_dim=feats_dim,
                    targets_dim=targets_dim,
                    template_shell_command=template_shell_command,
                    randomize=randomize,
                    max_time=max_time,
                    max_utt=max_utt,
                    frame_shift=frame_shift,
                    mapped=mapped)

        self.fake_lats = fake_lats
        self.lat2idx = {}

        if not self.fake_lats:
            with open(lat_scp, 'r') as lats:
                for line in lats:
                    utt, xxx = line.strip().split(None, 1)
                    if utt not in self.lat2idx.keys():
                        if len(self.lat2idx) == 0:
                            self.lat2idx[utt] = 0
                        else:
                            self.lat2idx[utt] = max(self.lat2idx.values())+1

            fi_set = set(self.files_info.keys())
            ai_set = set(self.align_info.keys())
            lat_set = set(self.lat2idx.keys())
            iset = set.intersection(fi_set, ai_set, lat_set)
        else:
            iset = set.intersection(fi_set, ai_set)

        new_files_info, new_align_info, new_lat2idx = {}, {}, {}
        for k in iset:
            new_files_info[k] = self.files_info[k]
            new_align_info[k] = self.align_info[k]
            new_lat2idx[k] = self.lat2idx[k]

        self.files_info = new_files_info
        self.align_info = new_align_info
        self.lat2idx = new_lat2idx

        self._num_examples = self._recount_examples(self.align_info)

        #update file list to resamble the actual intersetion
        old_list_size = self.list_size
        new_files_list = []
        for scp_entry in self.files_list:
            [utt, path] = scp_entry.split(' ', 1)
            if utt in self.files_info.keys():
                new_files_list.append(scp_entry)
        self.files_list = new_files_list
        self.list_size = len(self.files_list)

        log.warning("The intersection of features, targets and den-lattices results in %i "
                    "data-points (%i utterances, %i skipped)."
                    % (self._num_examples, self.list_size, old_list_size-self.list_size))

        feats_space = VectorSpace(dim=self.feats_dim)
        uttid = VectorSpace(dim=1)
        targets_space = VectorSpace(dim=self.targets_dim)
        self.data_spec = (CompositeSpace([feats_space, targets_space, uttid]), ('features', 'targets', 'utt_id'))

    def __iter__(self):
        return self

    def reset(self):
        super(KaldiSeqAlignFeatsProviderUtt, self).reset()

    def next(self):

        try:
            features, labels = super(KaldiSeqAlignFeatsProviderUtt, self).next()
        except StopIteration:
            raise StopIteration

        utt_id = None
        if (features is not None and labels is not None):
            utt_path = self.files_list[self.index-1] #ugly way to do so!
            utt = utt_path.split(" ")[0]
            if utt in self.lat2idx.keys():
                utt_id = self.lat2idx[utt]

        return features, labels, utt_id

    def num_classes(self):
        return [self.targets_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class FrameShuffler(object):
    def __init__(self,
                 utt_provider,
                 shuffling_window=2**15,
                 splice_preprocessor=None):

        self.utt_provider = utt_provider
        self.shuffling_window = shuffling_window
        self.splice_preprocessor = splice_preprocessor
        self.finished = False

        self.data_specs = self.utt_provider.get_data_specs()
        self.num_sources = len(self.data_specs[1])

    def reset(self):
        self.utt_provider.reset()
        self.finished = False

    def __iter__(self):
        return self

    def next(self):

        if self.finished:
            raise StopIteration

        try:
            buffer = None
            num_frames_read = 0
            while num_frames_read <= self.shuffling_window:
                utt = self.utt_provider.next()
                assert isinstance(utt, (tuple, list)) and\
                       len(utt) == self.num_sources, (
                    "Expected to get an data-point as an iterable"
                    " tuple or list following data specs, but got %s" % str(type(utt))
                )
                #filter out possible Nones here
                if any(u is None for u in utt):
                    continue
                num_frames_read += utt[0].shape[0]
                buffer.append(utt)
        except StopIteration:
            self.finished = True

        #convert from [(x1,y1,..), (x2,y2,...),...] to
        # [(x1,x2,...),(y1,y2,...)...]
        to_shuffling = zip(*buffer)
        assert len(to_shuffling) == self.num_sources, (
            "Unzipped list of unexpected length %i instead of %i spaces." % \
                    (len(to_shuffling), len(self.num_sources))
        )

        shuffled=[]
        rng_state = numpy.random.get_state()
        for i, u in enumerate(to_shuffling):
            space_data = numpy.concatenate(u, axis=0)

            #if true, splice frames before shuffling
            if i == 0 and self.splice_preprocessor is not None:
                assert self.data_specs[1][0] == 'features', (
                    "Expected to read splice data space 'features'"
                    " but got %s " % self.data_specs[1][0]
                )
                space_data = self.splice_preprocessor(space_data)

            numpy.random.set_state(rng_state)
            numpy.random.shuffle(space_data)
            shuffled.append(space_data)
        rval = zip(*shuffled)

        return tuple(rval)

    def num_classes(self):
        return self.utt_provider.num_classes()

    @property
    def num_examples(self):
        return self.utt_provider.num_examples

    def get_data_specs(self):
        return self.data_spec


class CICDKaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    def __init__(self,
                 feats_scp,
                 aligns_scp_cd,
                 aligns_scp_ci,
                 feats_dim,
                 targets_cd_dim,
                 targets_ci_dim,
                 template_shell_command=None,
                 randomize=False,
                 frame_shift=10,
                 max_utt=-1,
                 max_time=-1):
        """

        :param feats_scp:
        :param aligns_scp_cd:
        :param aligns_scp_ci:
        :param template_shell_command:
        :param randomize:
        :param max_utt:
        :param max_time:
        :return:
        """
        super(CICDKaldiAlignFeatsProviderUtt, self). \
            __init__(feats_scp=feats_scp,
                     feats_dim=feats_dim,
                     template_shell_command=template_shell_command,
                     randomize=randomize,
                     max_utt=max_utt)

        self.targets_cd_dim = targets_cd_dim
        self.targets_ci_dim = targets_ci_dim
        self.frame_shift = frame_shift
        self._frame_shift_in_sec = self.frame_shift / 1000.0
        self._utt_skipped = 0
        self._num_examples = 0

        files_info = {}
        for scp_entry in self.files_list:
            [utt, path] = scp_entry.split(' ', 1)
            files_info[utt] = scp_entry

        try:
            align_info_cd, num_examples_cd, num_classes_cd = \
                read_kaldi_aligns(aligns_scp_cd)
            align_info_m, num_examples_m, num_classes_m = \
                read_kaldi_aligns(aligns_scp_ci)
        except IOError as e:
            raise e

        fi_set = set(files_info.keys())
        aicd_set = set(align_info_cd.keys())
        aim_set = set(align_info_m.keys())
        iset = set.intersection(fi_set, aicd_set, aim_set)

        self.files_info, self.align_info_cd, self.align_info_m = {}, {}, {}
        for k in iset:
            self.files_info[k] = files_info[k]
            self.align_info_cd[k] = align_info_cd[k]
            self.align_info_m[k] = align_info_m[k] - 1 # convert monophones to 0-based indexing

        self._num_examples = self._recount_examples(self.align_info_cd)
        num_examples_m = self._recount_examples(self.align_info_m)

        #assert self._num_examples == num_examples_m, (
        #    "Number of training targets should be the same for both tasks" \
        #    " while got %i for cd and %i for ci targets" % (self._num_examples, num_examples_m)
        #)

        log.warning("Loaded %i feature files, %i context-dependent and %i monophone alignemts" \
                    % (len(files_info), len(align_info_cd), len(align_info_m)))
        log.warning("The intersection of those give in total %i data-points." % self._num_examples)
        log.warning("Num of classes is %i (cd) and %i (m) " \
                    % (num_classes_cd, num_classes_m))

        # when asked only subset of data, limit the lists here (given they are large enough at first place)
        # and update corresponding statistics
        if 0 < max_time < (self._num_examples * self._frame_shift_in_sec):
            log.warning('Limiting subset to %d seconds' % max_time)
            self.randomize = False
            new_aligns_info_cd = {}
            new_aligns_info_m = {}
            new_files_list = []
            examples_loaded, idx = 0, 0
            while examples_loaded * self._frame_shift_in_sec < max_time:
                scp_entry = self.files_list[idx]
                idx += 1
                [utt, path] = scp_entry.split(' ', 1)
                if utt not in self.align_info_cd:
                    continue
                new_files_list.append(scp_entry)
                new_aligns_info_cd[utt] = self.align_info_cd[utt]
                new_aligns_info_m[utt] = self.align_info_m[utt]
                examples_loaded += new_aligns_info_cd[utt].shape[0]

            # alter variables w.r.t new timings
            self.align_info_cd = new_aligns_info_cd
            self.align_info_m = new_aligns_info_m
            self.files_list = new_files_list
            self.list_size = len(self.files_list)
            self._num_examples = examples_loaded  # to make Trainer happy it showed all examples it supposed to

            log.warning("Time limited data gives %i data-points." % self._num_examples)

        feats_space = VectorSpace(dim=self.feats_dim)
        cd_space = VectorSpace(dim=self.targets_cd_dim)
        ci_space = VectorSpace(dim=self.targets_ci_dim)
        space = CompositeSpace([feats_space, cd_space, ci_space])
        source = ('features', 'targets_cd', 'targets_ci')
        self.data_spec = (space, source)

    def _recount_examples(self, align_info):
        num_examples = 0
        for align in align_info.keys():
            num_examples += numpy.prod(align_info[align].shape)
        return num_examples

    def __iter__(self):
        return self

    def reset(self):
        super(CICDKaldiAlignFeatsProviderUtt, self).reset()
        self.utt_skipped = 0

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            if self._utt_skipped > 0:
                log.warning('KaldiAlignFeatsProviderUtt: Skipped %i utterances out of %i' %
                            (self._utt_skipped, len(self.files_list)))
            raise StopIteration

        utt_path = self.files_list[self.index]
        utt_id = utt_path.split(" ")[0]
        none_tuple = (None, None, None)

        if utt_id not in self.files_info:
            self.index += 1
            return none_tuple

        features = None
        try:
            features = read_ark_entry_from_archive(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipped', str(e))
            self._utt_skipped += 1

        self.index += 1

        if features is None:
            return none_tuple

        labels_cd = self.align_info_cd[utt_id]
        labels_m = self.align_info_m[utt_id]

        # that shouldn't happen at this point
        if (features.shape[0] != labels_cd.shape[0]) or (features.shape[0] != labels_m.shape[0]):
            log.warning('Alignments for %s have %i frames while the utt has %i. Skipping' % \
                        (utt_path, labels_cd.shape[0], features.shape[0]))
            return none_tuple

        return features, labels_cd, labels_m

    def num_classes(self):
        return [self.targets_cd_dim, self.targets_ci_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class SequenceKaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    """A provider providing a featrues, alignments and lattice
     posteriors.
    """
    def __init__(self, feats_provider, lattice_provider):
        self.feats_provider = feats_provider
        self.lattice_provider = lattice_provider

    def __iter__(self):
        return self

    def next(self):

        try:

            acoustics = self.feats_provider.next()
            #posteriors

        except StopIteration:
            raise StopIteration


class MultiStreamCall(Process):
    def __init__(self, thread_id, in_queue, out_queue):
        super(MultiStreamCall, self).__init__(name=thread_id)
        self.thread_id = thread_id
        self.in_queue = in_queue
        self.out_queue = out_queue

    def run(self):
        #print 'Starting a %s'%self.thread_id
        scp_entry = self.in_queue.get(block=True)
        while scp_entry is not None:
            try:
                features = read_ark_entry_from_archive(scp_entry)
                self.out_queue.put(features)
            except Exception as e:
                print e
                self.out_queue.put(None)
            scp_entry = self.in_queue.get(block=True)
            #print 'Finishing %s'%self.thread_id


class MultiStreamKaldiAlignFeatsProviderUtt(KaldiAlignFeatsProviderUtt):
    def __init__(self,
                 file_scps,
                 align_scp,
                 feats_dim,
                 targets_dim,
                 randomize=False,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False,
                 concatenated=True):

        assert file_scps is not None and len(file_scps) > 1

        try:

            super(MultiStreamKaldiAlignFeatsProviderUtt, self)\
                .__init__(feats_scp=file_scps[0],
                          aligns_scp=align_scp,
                          feats_dim=feats_dim,
                          targets_dim=targets_dim,
                          template_shell_command=None,
                          randomize=False,
                          frame_shift=frame_shift,
                          max_utt=max_utt,
                          mapped=mapped)

            self.concatenated = concatenated
            utt_paths = []
            # load the lists splitted into UTTIDs (keys) and PATHs into separate dictionaries
            for f in file_scps:
                dp, dpd = ListDataProvider(f), {}
                for line in dp.files_list:
                    [utt, path] = line.split(' ', 1)
                    dpd[utt] = line
                utt_paths.append(dpd)
            self.num_streams = len(utt_paths)

            # now agree with aligns and get rid of any missing feats for any of the streams with the given UTTID
            self.utt_infos = {}
            for akey in self.align_info:
                paths, missing_paths = [], []
                for i in xrange(0, len(utt_paths)):
                    if akey in utt_paths[i]:
                        paths.append(utt_paths[i][akey])
                    else:
                        missing_paths.append(i)
                if len(missing_paths) == 0:
                    self.utt_infos[akey] = paths
                else:
                    print 'UTTID %s - not found feats for the following stream IDs : %s' % \
                          (akey, ", ".join(str(x) for x in missing_paths))

            self.keys = self.utt_infos.keys()
            if randomize is True:
                random.shuffle(self.keys)

            # prepare (and run) stream providing threads
            self.stream_threads, self.stream_inqueues, self.stream_outqueues = [], [], []
            for s in xrange(0, self.num_streams):
                self.stream_inqueues.append(Queue(maxsize=1))
                self.stream_outqueues.append(Queue(maxsize=1))
                self.stream_threads.append(
                    MultiStreamCall('Stream-%i' % s, self.stream_inqueues[s], self.stream_outqueues[s]))
                self.stream_threads[s].start()

            if self.concatenated:
                feats_space = VectorSpace(dim=self.feats_dim*self.num_streams)
                targets_space = VectorSpace(dim=self.targets_dim)
                self.data_spec = (CompositeSpace((feats_space, targets_space)), ('features', 'targets'))

        except IOError as e:
            raise e

    def __iter__(self):
        return self

    def reset(self):
        if self.randomize is True:
            random.shuffle(self.keys)
        self.index = 0

        for s in xrange(0, self.num_streams):
            self.stream_threads[s].terminate()

        self.stream_threads, self.stream_inqueues, self.stream_outqueues = [], [], []
        for s in xrange(0, self.num_streams):
            self.stream_inqueues.append(Queue(maxsize=1))
            self.stream_outqueues.append(Queue(maxsize=1))
            self.stream_threads.append(
                MultiStreamCall('Stream-%i' % s, self.stream_inqueues[s], self.stream_outqueues[s]))
            self.stream_threads[s].start()

    def next(self):
        if self.index >= len(self.utt_infos) or (0 < self.max_utt <= self.index):
            for s in xrange(0, self.num_streams):
                self.stream_inqueues[s].put(None)
            raise StopIteration

        utt_id = self.keys[self.index]
        self.index += 1

        features, labels = None, None

        if utt_id in self.align_info:
            labels = self.align_info[utt_id]
        else:
            # print 'No alignments found for utterannce: %s\n\tIndex %d: %d alignments; %d feats'%(utt_id, self.index, len(self.align_info), len(self.files_list))
            return features, labels

        utt_paths = self.utt_infos[utt_id]
        feats_list = [None] * self.num_streams

        try:
            for s in xrange(0, self.num_streams):
                self.stream_inqueues[s].put(utt_paths[s])
            for s in xrange(0, self.num_streams):  # this loop and queue secures proper synchronisation
                feats_list[s] = self.stream_outqueues[s].get(block=True)
        except Exception as e:
            print 'Something failed for %s: ' % utt_paths[0], e # , align_tuple[1]

        for i in xrange(0, len(feats_list)):
            if feats_list[i] is None:
                return None, None

        for feats in feats_list:
            if feats.shape[0] != labels.shape[0]:
                print 'Alignments for %s have %i frames while the utt has %i. Skipping' % \
                      (utt_paths[0], labels.shape[0], features.shape[0])
                return feats_list, None

        if self.concatenated is False:
            return feats_list, labels

        features = numpy.concatenate(feats_list, axis=1)  # concatenate the channels to make one big vector

        return features, labels

    def get_data_specs(self):
        return self.data_spec
