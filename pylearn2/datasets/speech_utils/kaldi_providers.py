__authors__ = "Pawel Swietojanski"
__copyright__ = "Copyright 2013, University of Edinburgh"
__credits__ = ["Pawel Swietojanski"]
__license__ = "3-clause BSD"
__maintainer__ = "Pawel Swietojanski"
__email__ = "p.swietojanski@ed.ac.uk"

import numpy
import struct
import random
import logging

from multiprocessing import Process, Queue, Pool

from string import Template
from StringIO import StringIO
from pylearn2.datasets.speech_utils.providers import ListDataProvider, make_shell_call
from pylearn2.space import CompositeSpace, Conv2DSpace, VectorSpace

log = logging.getLogger(__name__)


def read_kaldi_matrix(buffer):
    descr = struct.unpack('<xcccc', buffer.read(5))  # read 0B{F,D}{V,M,C}[space], function tested for 0BFM types only

    binary_mode = descr[0]
    repr_type = descr[1]
    cont_type = descr[2]

    assert binary_mode == "B"

    if (repr_type == 'F'):
        dtype = numpy.dtype(numpy.float32)
    elif (repr_type == 'D'):
        dtype = numpy.dtype(numpy.float64)
    else:
        raise ValueError('Wrong representation type in Kaldi header (is feats '
                        'compression enabled? - this is not supported in the '
                        'current version. Feel free to add this functionality.): %c' % (repr_type))

    rows, cols = 1, 1
    if (cont_type == 'M'):
        p1, rows = struct.unpack('<bi', buffer.read(5))  # bytes from 5 to 10
        p2, cols = struct.unpack('<bi', buffer.read(5))  # bytes from 10 to 15
        assert p1 == 4 and p2 == 4  # Number of bytes dimensionality is stored?
    elif (cont_type == 'V'):
        p1, rows = struct.unpack('<bi', buffer.read(5))  # bytes from 5 to 10
        assert p1 == 4
    else:
        raise Exception('Wrong container type in Kaldi header: %c' % (cont_type))

    assert rows > 0 and cols > 0  # just a range sanity checks
    assert rows < 360000 and cols < 30000  # just a sensible range sanity checks

    result = numpy.frombuffer(buffer.read(rows * cols * dtype.itemsize), dtype=dtype)
    if (cont_type == 'M'):
        result = numpy.reshape(result, (rows, cols))

    return result


def read_uttid(buffer):
    uttid = ''
    c = buffer.read(1)
    while c != ' ' and c != '':
        uttid += c
        c = buffer.read(1)
    return uttid


def read_ark_entry_from_buffer(buffer):
    """Reads a single Kaldi table archive entry and returns a tuple (uttid, ndarray)"""
    uttid = read_uttid(buffer)
    if uttid == '':
        return ''  # sygnalize EOF or pipe
    mtrx = None
    try:
        mtrx = read_kaldi_matrix(buffer)  # if this fails will raise (some) exception
    except Exception as e:
        raise e
    return (uttid, mtrx)


def read_ark_entry_from_archive(scp_entry):
    """Reads a single Kaldi table archive entry and returns a numpy array"""

    uttid, path = scp_entry.split(" ")
    ark_path, file_pos = path.split(":")

    try:
        ark = open(ark_path, 'rb')
        ark.seek(int(file_pos))
        feats = read_kaldi_matrix(ark)
        ark.close()
    except Exception as e:
        raise e

    return feats


def write_ark_entry_to_buffer(buffer, uttid, activations):
    activations = numpy.asarray(activations, dtype='float32')
    rows, cols = activations.shape
    buffer.write(struct.pack('<%ds' % (len(uttid)), uttid))
    buffer.write(struct.pack('<cxcccc', ' ', 'B', 'F', 'M', ' '))
    buffer.write(struct.pack('<bi', 4, rows))
    buffer.write(struct.pack('<bi', 4, cols))
    buffer.write(activations)


def read_kaldi_aligns(align_filename):
    f = open(align_filename, 'r')
    align_info = {}
    num_lines_align, num_examples, num_classes = 0, 0, 0
    for line in f:
        num_lines_align += 1
        line = line.strip()
        if len(line) < 1:
            continue  # remove empty lines
        [utt, alignment] = line.split(' ', 1)
        # skip empty alignments (these shouldn't be generated by Kaldi anyway)
        if len(alignment) < 1:
            log.warning('Empty alignment for utterance %s' % utt)
            continue
        align_info[utt] = numpy.loadtxt(StringIO(alignment), dtype=numpy.int32)
        tmp = align_info[utt].max()
        if tmp > num_classes:
            num_classes = tmp
        num_examples += align_info[utt].shape[0]
    f.close()
    return align_info, num_examples, num_classes


class KaldiFeatsProviderUtt(ListDataProvider):
    def __init__(self,
                 feats_scp,
                 feats_dim,
                 template_shell_command=None,  # "copy-feats-1file scp:\"echo ${SCP_ENTRY}|\"",
                 randomize=False,
                 max_utt=-1):
        """

        :param feats_scp:
        :param dim:
        :param template_shell_command:
        :param randomize:
        :param max_utt:
        :return:
        """

        super(KaldiFeatsProviderUtt, self).__init__(feats_scp)
        self.max_utt = max_utt
        self.randomize = randomize
        self.template_shell_command = (
            Template(template_shell_command) if (template_shell_command != None) else None)
        self.feats_dim = feats_dim
        if self.randomize is True:
            random.shuffle(self.files_list)

        self.data_specs = (VectorSpace(dim=self.feats_dim), 'features')

    def reset(self):
        self.index = 0
        if self.randomize is True:
            random.shuffle(self.files_list)

    def __iter__(self):
        return self

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            raise StopIteration

        utt_path = self.files_list[self.index]
        features = None
        try:
            if self.template_shell_command is None:
                features = read_ark_entry_from_archive(utt_path)
            else:
                features = self.shell_call(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipping.' % e)
        self.index += 1

        return features

    def shell_call(self, utt_path):

        shell_call_cmd = self.template_shell_command.substitute(SCP_ENTRY=utt_path)
        buffer_tuple = make_shell_call(shell_call_cmd)

        if buffer_tuple is None:
            raise Exception('Cannot extract a matrix using shell call %s .' % shell_call_cmd)

        features = read_kaldi_matrix(StringIO(buffer_tuple[0]))

        return (features,)

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_specs


class KaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    """Data provider reading Kaldi archives and returning utterance-based
    features and associated ground-truth labels from alignment files
    """

    def __init__(self,
                 feats_scp,
                 aligns_scp,
                 feats_dim,
                 targets_dim,
                 template_shell_command=None,
                 randomize=False,
                 max_time=-1,
                 max_utt=-1,
                 frame_shift=10,
                 mapped=False):
        """

        :param feats_scp:
        :param aligns_scp:
        :param template_shell_command:
        :param randomize:
        :param max_time:
        :param max_utt:
        :param frame_shift:
        :param mapped:
        :return: a tuple (features, targets) for a given utterance
        """

        super(KaldiAlignFeatsProviderUtt, self).\
            __init__(feats_scp=feats_scp,
                    feats_dim=feats_dim,
                    template_shell_command=template_shell_command,
                    randomize=randomize,
                    max_utt=max_utt)

        self.frame_shift = frame_shift
        self.targets_dim = targets_dim
        self.mapped = mapped
        self._frame_shift_in_sec = self.frame_shift / 1000.0
        self.utt_skipped = 0
        self._num_examples = 0

        files_info = {}
        for scp_entry in self.files_list:
            [utt, path] = scp_entry.split(' ', 1)
            files_info[utt] = scp_entry

        try:
            align_info, num_examples, num_classes = \
                read_kaldi_aligns(aligns_scp)
        except IOError as e:
            raise e

        fi_set = set(files_info.keys())
        ai_set = set(align_info.keys())
        iset = set.intersection(fi_set, ai_set)

        #monophones in Kaldi are indexed from 1, mapp
        # this to 0-based indexing
        mapping = 0
        if self.mapped:
            log.warning("Mapping indexing from 1-based to 0-based (Kaldi monophones)")
            mapping = 1

        self.files_info, self.align_info = {}, {}
        for k in iset:
            self.files_info[k] = files_info[k]
            self.align_info[k] = align_info[k] - mapping

        assert len(self.align_info) == len(self.files_info)
        self._num_examples = self._recount_examples(self.align_info)

        log.warning("Loaded %i feature files and %i associated alignments" \
                    % (len(files_info), len(align_info)))
        log.warning("The intersection of those give in total %i "
                    "data-points." % self._num_examples)
        log.warning("Num of classes found in alignemnts is %i." % num_classes)

        # when asked only subset of data, limit the lists here (given they are large enough at first place)
        # and update corresponding statistics
        if 0 < max_time < (self._num_examples * self._frame_shift_in_sec):
            log.warning('Limiting subset to %d seconds' % max_time)
            self.randomize = False
            new_aligns_info = {}
            new_files_list = []
            examples_loaded, idx = 0, 0
            while examples_loaded * self._frame_shift_in_sec < max_time:
                scp_entry = self.files_list[idx]
                idx += 1
                [utt, path] = scp_entry.split(' ', 1)
                if utt not in self.align_info:
                    continue
                new_files_list.append(scp_entry)
                new_aligns_info[utt] = self.align_info[utt]
                examples_loaded += new_aligns_info[utt].shape[0]

            # alter variables w.r.t new timings
            self.align_info = new_aligns_info
            self.files_list = new_files_list
            self.list_size = len(self.files_list)
            self._num_examples = examples_loaded  # to make Trainer happy it showed all examples it supposed to

        feats_space = VectorSpace(dim=self.feats_dim)
        targets_space = VectorSpace(dim=self.targets_dim)
        self.data_spec = (CompositeSpace((feats_space, targets_space)), ('features', 'targets'))

    def _recount_examples(self, align_info):
        num_examples = 0
        for align in align_info.keys():
            num_examples += numpy.prod(align_info[align].shape)
        return num_examples

    def __iter__(self):
        return self

    def reset(self):
        super(KaldiAlignFeatsProviderUtt, self).reset()
        self.utt_skipped = 0

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            if self.utt_skipped > 0:
                log.warning('KaldiAlignFeatsProviderUtt: Skipped %i utterances out of %i' % (
                    self.utt_skipped, len(self.files_list)))
            raise StopIteration

        utt_path = self.files_list[self.index]
        utt_id = utt_path.split(" ")[0]
        features, labels = None, None
        try:
            if self.template_shell_command is None:
                features = read_ark_entry_from_archive(utt_path)
            else:
                features = self.shell_call(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipping.' % e)

        self.index += 1

        if features is None:
            return (None, None), utt_path

        if utt_id in self.align_info:
            labels = self.align_info[utt_id]
        else:
            self.utt_skipped += 1
            return features, None

        # that shouldn't happen at this point
        if features.shape[0] != labels.shape[0]:
            log.warning('Alignments for %s have %i frames while the utt has %i. Skipping' % \
                        (utt_path, labels.shape[0], features.shape[0]))
            self.utt_skipped += 1
            return features, None

        return features, labels

    def num_classes(self):
        return [self.targets_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class FrameShuffler(object):
    def __init__(self,
                 utt_provider,
                 shuffling_window=2**15,
                 splice_preprocessor=None):

        self.utt_provider = utt_provider
        self.shuffling_window = shuffling_window
        self.splice_preprocessor = splice_preprocessor
        self.finished = False

        self.data_specs = self.utt_provider.get_data_specs()
        self.num_sources = len(self.data_specs[1])

    def reset(self):
        self.utt_provider.reset()
        self.finished = False

    def __iter__(self):
        return self

    def next(self):

        if self.finished:
            raise StopIteration

        try:
            buffer = None
            num_frames_read = 0
            while num_frames_read <= self.shuffling_window:
                utt = self.utt_provider.next()
                assert isinstance(utt, (tuple, list)) and\
                       len(utt) == self.num_sources, (
                    "Expected to get an data-point as an iterable"
                    " tuple or list following data specs, but got %s" % str(type(utt))
                )
                #filter out possible Nones here
                if any(u is None for u in utt):
                    continue
                num_frames_read += utt[0].shape[0]
                buffer.append(utt)
        except StopIteration:
            self.finished = True

        #convert from [(x1,y1,..), (x2,y2,...),...] to
        # [(x1,x2,...),(y1,y2,...)...]
        to_shuffling = zip(*buffer)
        assert len(to_shuffling) == self.num_sources, (
            "Unzipped list of unexpected length %i instead of %i spaces." % \
                    (len(to_shuffling), len(self.num_sources))
        )

        shuffled=[]
        rng_state = numpy.random.get_state()
        for i, u in enumerate(to_shuffling):
            space_data = numpy.concatenate(u, axis=0)

            #if true, splice frames before shuffling
            if i == 0 and self.splice_preprocessor is not None:
                assert self.data_specs[1][0] == 'features', (
                    "Expected to read splice data space 'features'"
                    " but got %s " % self.data_specs[1][0]
                )
                space_data = self.splice_preprocessor(space_data)

            numpy.random.set_state(rng_state)
            numpy.random.shuffle(space_data)
            shuffled.append(space_data)
        rval = zip(*shuffled)

        return tuple(rval)

    def num_classes(self):
        return self.utt_provider.num_classes()

    @property
    def num_examples(self):
        return self.utt_provider.num_examples

    def get_data_specs(self):
        return self.data_spec


class CICDKaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    def __init__(self,
                 feats_scp,
                 aligns_scp_cd,
                 aligns_scp_ci,
                 feats_dim,
                 targets_cd_dim,
                 targets_ci_dim,
                 template_shell_command=None,
                 randomize=False,
                 frame_shift=10,
                 max_utt=-1,
                 max_time=-1):
        """

        :param feats_scp:
        :param aligns_scp_cd:
        :param aligns_scp_ci:
        :param template_shell_command:
        :param randomize:
        :param max_utt:
        :param max_time:
        :return:
        """
        super(CICDKaldiAlignFeatsProviderUtt, self). \
            __init__(feats_scp=feats_scp,
                     feats_dim=feats_dim,
                     template_shell_command=template_shell_command,
                     randomize=randomize,
                     max_utt=max_utt)

        self.targets_cd_dim = targets_cd_dim
        self.targets_ci_dim = targets_ci_dim
        self.frame_shift = frame_shift
        self._frame_shift_in_sec = self.frame_shift / 1000.0
        self._utt_skipped = 0
        self._num_examples = 0

        files_info = {}
        for scp_entry in self.files_list:
            [utt, path] = scp_entry.split(' ', 1)
            files_info[utt] = scp_entry

        try:
            align_info_cd, num_examples_cd, num_classes_cd = \
                read_kaldi_aligns(aligns_scp_cd)
            align_info_m, num_examples_m, num_classes_m = \
                read_kaldi_aligns(aligns_scp_ci)
        except IOError as e:
            raise e

        fi_set = set(files_info.keys())
        aicd_set = set(align_info_cd.keys())
        aim_set = set(align_info_m.keys())
        iset = set.intersection(fi_set, aicd_set, aim_set)

        self.files_info, self.align_info_cd, self.align_info_m = {}, {}, {}
        for k in iset:
            self.files_info[k] = files_info[k]
            self.align_info_cd[k] = align_info_cd[k]
            self.align_info_m[k] = align_info_m[k] - 1 # convert monophones to 0-based indexing

        self._num_examples = self._recount_examples(self.align_info_cd)
        num_examples_m = self._recount_examples(self.align_info_m)

        #assert self._num_examples == num_examples_m, (
        #    "Number of training targets should be the same for both tasks" \
        #    " while got %i for cd and %i for ci targets" % (self._num_examples, num_examples_m)
        #)

        log.warning("Loaded %i feature files, %i context-dependent and %i monophone alignemts" \
                    % (len(files_info), len(align_info_cd), len(align_info_m)))
        log.warning("The intersection of those give in total %i data-points." % self._num_examples)
        log.warning("Num of classes is %i (cd) and %i (m) " \
                    % (num_classes_cd, num_classes_m))

        # when asked only subset of data, limit the lists here (given they are large enough at first place)
        # and update corresponding statistics
        if 0 < max_time < (self._num_examples * self._frame_shift_in_sec):
            log.warning('Limiting subset to %d seconds' % max_time)
            self.randomize = False
            new_aligns_info_cd = {}
            new_aligns_info_m = {}
            new_files_list = []
            examples_loaded, idx = 0, 0
            while examples_loaded * self._frame_shift_in_sec < max_time:
                scp_entry = self.files_list[idx]
                idx += 1
                [utt, path] = scp_entry.split(' ', 1)
                if utt not in self.align_info_cd:
                    continue
                new_files_list.append(scp_entry)
                new_aligns_info_cd[utt] = self.align_info_cd[utt]
                new_aligns_info_m[utt] = self.align_info_m[utt]
                examples_loaded += new_aligns_info_cd[utt].shape[0]

            # alter variables w.r.t new timings
            self.align_info_cd = new_aligns_info_cd
            self.align_info_m = new_aligns_info_m
            self.files_list = new_files_list
            self.list_size = len(self.files_list)
            self._num_examples = examples_loaded  # to make Trainer happy it showed all examples it supposed to

            log.warning("Time limited data gives %i data-points." % self._num_examples)

        feats_space = VectorSpace(dim=self.feats_dim)
        cd_space = VectorSpace(dim=self.targets_cd_dim)
        ci_space = VectorSpace(dim=self.targets_ci_dim)
        space = CompositeSpace([feats_space, cd_space, ci_space])
        source = ('features', 'targets_cd', 'targets_ci')
        self.data_spec = (space, source)

    def _recount_examples(self, align_info):
        num_examples = 0
        for align in align_info.keys():
            num_examples += numpy.prod(align_info[align].shape)
        return num_examples

    def __iter__(self):
        return self

    def reset(self):
        super(CICDKaldiAlignFeatsProviderUtt, self).reset()
        self.utt_skipped = 0

    def next(self):
        if (self.index >= self.list_size) or (self.max_utt > 0 and self.index >= self.max_utt):
            if self._utt_skipped > 0:
                log.warning('KaldiAlignFeatsProviderUtt: Skipped %i utterances out of %i' %
                            (self._utt_skipped, len(self.files_list)))
            raise StopIteration

        utt_path = self.files_list[self.index]
        utt_id = utt_path.split(" ")[0]
        none_tuple = (None, None, None)

        if utt_id not in self.files_info:
            self.index += 1
            return none_tuple

        try:
            features = read_ark_entry_from_archive(utt_path)
        except Exception as e:
            log.warning('Cannot load file: %s. Skipped', str(e))
            self._utt_skipped += 1

        self.index += 1

        if features is None:
            return none_tuple

        labels_cd = self.align_info_cd[utt_id]
        labels_m = self.align_info_m[utt_id]

        # that shouldn't happen at this point
        if (features.shape[0] != labels_cd.shape[0]) or (features.shape[0] != labels_m.shape[0]):
            log.warning('Alignments for %s have %i frames while the utt has %i. Skipping' % \
                        (utt_path, labels_cd.shape[0], features.shape[0]))
            return none_tuple

        return features, labels_cd, labels_m

    def num_classes(self):
        return [self.targets_cd_dim, self.targets_ci_dim]

    @property
    def num_examples(self):
        return self._num_examples

    def get_data_specs(self):
        return self.data_spec


class SequenceKaldiAlignFeatsProviderUtt(KaldiFeatsProviderUtt):
    """A provider providing a featrues, alignments and lattice
     posteriors.
    """
    def __init__(self, feats_provider, lattice_provider):
        self.feats_provider = feats_provider
        self.lattice_provider = lattice_provider

    def __iter__(self):
        return self

    def next(self):

        try:

            acoustics = self.feats_provider.next()
            #posteriors

        except StopIteration:
            raise StopIteration

class MultiStreamCall(Process):
    def __init__(self, thread_id, in_queue, out_queue):
        super(MultiStreamCall, self).__init__(name=thread_id)
        self.thread_id = thread_id
        self.in_queue = in_queue
        self.out_queue = out_queue

    def run(self):
        # print 'Starting a %s'%self.thread_id
        scp_entry = self.in_queue.get(block=True)
        while (scp_entry is not None):
            try:
                features = read_ark_entry_from_archive(scp_entry)
                self.out_queue.put(features)
            except Exception as e:
                print e
                self.out_queue.put(None)
            scp_entry = self.in_queue.get(block=True)
            # print 'Finishing %s'%self.thread_id


class MultiStreamKaldiAlignFeatsProviderUtt(KaldiAlignFeatsProviderUtt):
    def __init__(self, files_paths_lists, align_file, template_shell_command, randomize=False,
                 subset=-1, mapped=False, concatenated=True):

        assert files_paths_lists != None and len(files_paths_lists) > 1

        try:
            super(MultiStreamKaldiAlignFeatsProviderUtt, self).__init__(files_paths_lists[0], align_file,
                                                                        template_shell_command,
                                                                        randomize=False, max_utt=subset,
                                                                        mapped=mapped)

            self.concatenated = concatenated
            utt_paths = []
            # load the lists splitted into UTTIDs (keys) and PATHs into separate dictionaries
            for f in files_paths_lists:
                dp, dpd = ListDataProvider(f), {}
                for line in dp.files_list:
                    [utt, path] = line.split(' ', 1)
                    dpd[utt] = line
                utt_paths.append(dpd)
            self.num_streams = len(utt_paths)

            # now agree with aligns and get rid of any missing feats for any of the streams with the given UTTID
            self.utt_infos = {}
            for akey in self.align_info:
                paths, missing_paths = [], []
                for i in xrange(0, len(utt_paths)):
                    if akey in utt_paths[i]:
                        paths.append(utt_paths[i][akey])
                    else:
                        missing_paths.append(i)
                if len(missing_paths) == 0:
                    self.utt_infos[akey] = paths
                else:
                    print 'UTTID %s - not found feats for the following stream IDs : %s' % \
                          (akey, ", ".join(str(x) for x in missing_paths))

            self.keys = self.utt_infos.keys()
            if randomize is True:
                random.shuffle(self.keys)

            # prepare (and run) stream providing threads
            self.stream_threads, self.stream_inqueues, self.stream_outqueues = [], [], []
            for s in xrange(0, self.num_streams):
                self.stream_inqueues.append(Queue(maxsize=1))
                self.stream_outqueues.append(Queue(maxsize=1))
                self.stream_threads.append(
                    MultiStreamCall('Stream-%i' % s, self.stream_inqueues[s], self.stream_outqueues[s]))
                self.stream_threads[s].start()

        except IOError as e:
            raise e

    def __iter__(self):
        return self

    def reset(self):
        if self.randomize is True:
            random.shuffle(self.keys)
        self.index = 0

        for s in xrange(0, self.num_streams):
            self.stream_threads[s].terminate()

        self.stream_threads, self.stream_inqueues, self.stream_outqueues = [], [], []
        for s in xrange(0, self.num_streams):
            self.stream_inqueues.append(Queue(maxsize=1))
            self.stream_outqueues.append(Queue(maxsize=1))
            self.stream_threads.append(
                MultiStreamCall('Stream-%i' % s, self.stream_inqueues[s], self.stream_outqueues[s]))
            self.stream_threads[s].start()

    def next(self):
        if ((self.index >= len(self.utt_infos)) or (self.max_utt > 0 and self.index >= self.max_utt)):
            for s in xrange(0, self.num_streams):
                self.stream_inqueues[s].put(None)
            raise StopIteration

        utt_id = self.keys[self.index]
        self.index += 1

        features, labels = None, None

        if utt_id in self.align_info:
            labels = self.align_info[utt_id]
        else:
            # print 'No alignments found for utterannce: %s\n\tIndex %d: %d alignments; %d feats'%(utt_id, self.index, len(self.align_info), len(self.files_list))
            return (features, labels), utt_id

        utt_paths = self.utt_infos[utt_id]
        feats_list = [None] * self.num_streams

        try:
            for s in xrange(0, self.num_streams):
                self.stream_inqueues[s].put(utt_paths[s])
            for s in xrange(0, self.num_streams):  # this loop and queue secures proper synchronisation
                feats_list[s] = self.stream_outqueues[s].get(block=True)
        except Exception as e:
            print 'Something failed: ', e, buffer_tuple[1]  # , align_tuple[1]

        for i in xrange(0, len(feats_list)):
            if (feats_list[i] is None):
                return (None, None), utt_id

        for feats in feats_list:
            if feats.shape[0] != labels.shape[0]:
                print 'Alignments for %s have %i frames while the utt has %i. Skipping' % \
                      (utt_path, labels.shape[0], features.shape[0])
                return (feats_list, None), utt_id

        if self.mapped == True:
            labels = labels - 1

        if self.concatenated is False:
            return (feats_list, labels), utt_id

        features = numpy.concatenate(feats_list, axis=1)  # concatenate the channels to make one big vector

        return (features, labels)

    def get_data_specs(self):
        raise NotImplementedError(str(type(self)) + " does not implement get_data_sepcs.")
