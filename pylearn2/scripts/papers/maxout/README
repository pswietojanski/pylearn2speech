The files in this directory recreate some of the experiments reported in the
paper

Maxout Networks. Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron
Courville, and Yoshua Bengio. arXiv 2013

If you use the code provided here, please cite that paper.

The experiments reproduced here are as follows:

1) MNIST permutation invariant result

The paper reports obtaining a test set error rate of 0.94%, the best ever
reported (as of this writing) for a multilayer perceptron with no unsupervised
pretraining. To reproduce this result, run

train.py mnist_pi.yaml
train.py mnist_pi_continued.yaml
print_monitor.py mnist_pi_continued.pkl | grep test_y_misclass

You should get 0.009399999999, i.e., 94 mistakes on the test set.

Note: you probably will want to run the above scripts with
THEANO_FLAGS="device=gpu,floatX=float32" for optimal speed, but if you don't
have a GPU it should work without one. I have, however, not tested this case.
The remaining results all require GPU as they are implemented using Alex Krizvhevsky's
CUDA convolution library.

2) MNIST result

The paper reports obtaining a test set error rate of 0.45%, the state of the
art for the MNIST dataset without data augmentation. To reproduce this result,
run:

THEANO_FLAGS="device=gpu,floatX=float32" train.py mnist.yaml
THEANO_FLAGS="device=gpu,floatX=float32" train.py mnist_continued.yaml
THEANO_FLAGS="device=gpu,floatX=float32" python compute_test_err.py mnist_continued.pkl

The final command should print out some progress messages followed by "0.0045"

3) CIFAR-10 result

The paper reports a test set error of 12.93% on the CIFAR-10 dataset,
which is the state of the art without data augmentation. To reproduce
this result, you must first have prepared a version of the CIFAR-10
dataset with global contrast normalization and whitening. To do so,
run pylearn2/scripts/datasets/make_cifar10_gcn_whitened.py. (If you
are in the LISA lab, don't do this. It has already been made for you)

After running make_cifar10_gcn_whitened, you can train the maxout model
by running

THEANO_FLAGS="device=gpu,floatX=float32" train.py cifar10.yaml

At this point, the model has only been trained on the first 40k examples.
Run
THEANO_FLAGS="device=gpu,floatX=float32" python compute_test_err.py cifar10_best.pkl

It should report a test error of 0.1405 at this point.

In the days ahead, we will provide our yaml config files for training on the
remaining 10k training examples, which reduces the test error to 0.1293.

4) CIFAR-100 result

In the days ahead, we will provide our yaml config files for getting the state of
the art on CIFAR-100.

5) SVHN

The paper reports a test error of 2.45 on the SVHN dataset, which is the state
of the art for a single model.

Since we can not fit all the data to memory we us PyTables hdf5 file format for storing
the dataset. By running svhn_pre-processing we make a local copy of the dataset in hdf5
and apply the pre-processing on it. Our pre-processing consists of first global contrast normalization
followed by local contrast normalization on each of the RGB channels.

export SVHN_LOCAL_PATH={some local folder}
python svhn_preprocessing.py

Afterwards we train our model using the svhn.yaml file

THEANO_FLAGS="device=gpu,floatX=float32" python train.py svhn.yaml

This should give the best validation error of 3.08% which corresponds to
test error of 2.50% at epoch 142.

Afterwards using the trick from this paper:

On the importance of momentum and initialization in deep learning,
Ilya Sutskever, James Martens, George Dahl, and Geoffery Hinton, ICML 2013

We can re-run the model from the previous best point by using smaller
learning rate which will result in best validation error of 3.07% and
test error of 2.47% after 9 more epochs.

THEANO_FLAGS="device=gpu,floatX=float32" python train.py svhn2.yaml
